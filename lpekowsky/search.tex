In the previous chapter we showed that interferometric detectors, such
as LIGO, are capable of encoding the presence of gravitational waves
in the phase shifts of light.  These shifts over time, or rather the
motion of the servos to prevent them, are recorded as the data stream
\darmerr.  As noted, this data stream will also contain noise from
several sources.  In this chapter we discuss a method to extract
signals, if present, from the noise and hence allow the LIGO and Virgo
collaborations to claim a direct detection of gravitational waves.

For the most part in this chapter we will disregard implementation
details.  In particular, we will treat quantities as continuous in
both time and magnitude.  In reality the data is sampled at 16,384 
Hz, and all time integrals should be replaced by sums.  Values are
also stored in a discrete form, although the resolution is no coarser
than the resolution of IEEE floating-point numbers.  Analysis codes
therefore do not need any special features to deal with this
discretization, beyond the usual care taken not to accumulate
numerical errors.  In particular, Fourier transforms, special
functions, and similar functionality can be provided by standard
code libraries.



\section{Detecting signals in noise}
\label{sec:ihope_match_filter}

There are many ways to search for evidence of gravitational waves in
noise and to a large extent the method used will depend on the nature
of the signal being sought.  In this chapter we focus on the method
used to search for the coalescence of compact binaries, as discussed
in chapter~\ref{ch:theory}.

\subsection{Random Processes}
\label{ssec:random_processes}

We start by modelling the noise in the instruments, following the
treatment in~\cite{BlandfordThorne}.  Seismic noise is not predictable
in any detailed way, and thermal and shot noise are quantum-mechanical
in nature and therefore can not be predicted even in principle.  The
noise is therefore a \emph{random process}.  Such a process is
described by a collection of probability density functions of the form

\begin{equation*}
\label{eq:pdfs}
p(y_n, t_n; y_{n-1}, t_{n-1}; \ldots y_0 t_0) dy_n dy_{n-1} \ldots
dy_0
\end{equation*}

which gives the probability that the value at time $t_0$ will will
lie between $y_0$ and $y_0 + dy_0$ and that the value at time $t_1$
will will lie between $y_1$ and $y_1 + dy_1$, and so on.

By considering a hypothetical ensemble of such processes we can 
construct average values of functions of the process at one or more
times.  For example the average value of the product $y(t_1)y(t_2)$,

\begin{equation*}
\langle y(t_1) y(t_2) \rangle = \int y_2 y_1
p(y_2, t_2; y_1, t_1)\, dy_2\, dy_1
\end{equation*}

We now make the following assumptions about the LIGO noise:

\begin{itemize}
\item That it is \emph{stationary}, the values of the
functions~\ref{eq:pdfs} depend only on the differences between the
times, and not any absolute external clock.  This is not necessary a
good model for seismic noise, but by breaking the analysis into small
chunks of time it will be accurate enough over the span of each.

\item That it is \emph{Gaussian}, that is, the functions~\ref{eq:pdfs}
are all of the form $\exp(-Y^T A Y)$ where $Y$ is a vector of $y$
values and  $A$ is a positive-definite matrix.  This is not
necessarily a good model for, eg, electrical noise, which is better
modeled as a sine wave with time-dependant random amplitude.  However,
again this will be approximately correct.  We will further assume that
the mean is 0 (eg, that the mirrors are just as likely to swing one
way as the other).

\item That it satisfies the \emph{ergodic hypothesis} so that we may
replace ensemble averages with time averages.

\end{itemize}

Now consider the quantity $S_y(f)$ called the \emph{power spectral
density}, defined as

\begin{equation}
\label{eq:psd1}
S_y(f) \equiv \lim_{T \to \infty} 
\frac{1}{T} \left| \int_{-T/2}^{T/2} (y(t) - \bar{y}(t))
e^{2 \pi i f t} dt \right|^2
\end{equation}

Using Parceval's theorem it can be shown that

\begin{equation*}
\int_0^\infty S_y(f)\, df = \sigma^2_y
\end{equation*}

That is, $S_y(f)$ measures the contribution of each frequency 
to the total variance of the process.

It can also be shown that 

\begin{equation}
\label{eq:psd2}
\langle \tilde{y}(f) \tilde{y}(f')\rangle = \frac{1}{2} S_y(f)
\delta(f-f')
\end{equation}

\subsection{The matched filter}
\label{ssec:matched_filter}

We now specialize to the case of LIGO.  We denote the noise in the
detector as $n(t)$, and a gravitational wave signal as $h(t)$.  The
output of the detector is then $s(t)=n(t)+h(t)$ data from the
instrument.  We seek a filter on the data that we can use to infer the
presence of the signal.

Consider the most general linear filter which  in the discrete case
would be

\begin{equation}
\hat{s} = \sum_i s_i K_i
\end{equation}

Since we will want a real result, we require the $K_i$ to be real.  In
the continuum limit this becomes

\begin{equation}
\hat{s} = \int_{-\infty}^\infty s(t) K(t)\, dt
\end{equation}

We now define the signal strength $S$ as the expected value of
$\hat{s}$ when the signal is present:

\begin{align*}
S &= \left\langle \hat{s} \right\rangle \\
&= \langle  \int_{-\infty}^\infty s(t) K(t)\, dt \rangle \\
&= \int_{-\infty}^\infty \langle s(t) K(t)\rangle \, dt \\
&= \int_{-\infty}^\infty \langle s(t) \rangle K(t) \, dt \\
&= \int_{-\infty}^\infty \langle n(t) + h(t) \rangle K(t) \, dt \\
&= \int_{-\infty}^\infty \left( \langle n(t) \rangle + \langle h(t)
\rangle \right)  K(t) \, dt \\
&= \int_{-\infty}^\infty \left( 0 + h(t) \right)  K(t) \, dt \\
&= \int_{-\infty}^\infty h(t) K(t) \, dt \\
\end{align*}

Now, since $K(t)$ is real we can replace it by its complex conjugate
and then apply Parseval's theorem to write this as

\begin{equation*}
S = \int_{-\infty}^\infty h(t) K^\star(t) \, dt
= \int_{-\infty}^\infty \tilde{h}(f) \tilde{K}^\star(f) \, df
\end{equation*}

We characterise the noise $N$ as the rms value of $\hat{s}$ when the
signal is absent:


\begin{align}
N^2 &= \langle \hat{s}^2(t) \rangle - \langle \hat{s}(t) \rangle^2 \\
&= \langle \hat{s}^2(t) \rangle  \\
&= \int_{-\infty}^\infty K(t) K(t') \langle n(t) n(t')
\rangle\,dt\,dt' \\
&= \int_{-\infty}^\infty dt\,dt' K(t) K(t') 
\int_{-\infty}^\infty df\,df' e^{2\pi i f t}e^{-2\pi i f' t'} \langle
\tilde{n}^\star(f) \tilde{n}(f')\rangle \\
\end{align}

Using equation~\ref{eq:psd2} this becomes

\begin{equation}
N^2 = \int_{-\infty}^\infty df\,\frac{1}{2} S_n(f) |\tilde{K}(f)|^2
\end{equation}

We now introduce a new function

\begin{equation}
\tilde{u}(f) = \frac{1}{2} S_n(f) \tilde{K}(f)
\end{equation}

In terms of which we can write the signal-to-noise ration $S/N$ as

\begin{equation}
\frac{S}{N} =
\frac
  {\int_{-\infty}^\infty df\,
   \frac
     {\tilde{h}(f) \tilde{u}^\star(f)}
     {(1/2) S_n(f)}}
  {\left[\int_{-\infty}^\infty df\,
   \frac
     {\tilde{u}(f) \tilde{u}^\star(f)}
     {(1/2) S_n(f)}\right]^{1/2}}
\end{equation}

This motivates the definition of an operator mapping pairs of
functions to real numbers

\begin{equation}
\label{eq:InnerProduct}
\InnerProduct{A|B} 
 = \int_{-\infty}^\infty df\,
   \frac
     {\tilde{A}(f) \tilde{B}^\star(f)}
     {(1/2) S_n(f)}
\end{equation}

This operator has the following properties

\begin{itemize}
\item Conjugate symmetry, $(x|y) = (y|x)^\star$
\item Linearity in the first argument $(ax + by|z) = a(x|z) + b(y|z)$ for
$a,b$ numbers and $x,y,z$ functions.  This follows from the linearity
of the Fourier transform.
\item Positive-definiteness $(x|x) \geq 0$ and $(x|x) = 0$ iff $x=0$.  This
follows from the positive-definiteness of the product $aa^\star$ for
$a \in \mathcal{C}$.
\end{itemize}

The operator has all the properties of an inner product on
the vector space of functions.  We may therefore consider

\[
\frac{u}{(u|u)}
\]

to be a normalized vector.

An important feature of this inner product, which we will use
repeatedly, is that the probability of obtaining any particular 
pattern $f(t)$ in the data is, up to normalization~\cite{Finn1992}

\begin{equation}
\label{eq:prob_of_signal}
p(f) \propto \exp\left(- \frac{1}{2} \InnerProduct{f|f} \right)
\end{equation}

Using equation~\ref{eq:InnerProduct} the SNR becomes

\begin{equation}
\label{eq:InnerProductSNR}
\rho = \frac{S}{N} = \frac{\InnerProduct{h|u}}{\InnerProduct{u|u}^{1/2}}
\end{equation}

where we introduce $\rho$ as the symbol we will use for SNR.

We now seek a function $u$ (and hence $K$) that will maximize $\rho$.
In this form it is clear that $u$ and $h$ must be parallel, and
therefore

\begin{equation}
\tilde{K}(f) \propto \frac{\tilde{h}}{S_n(f)}
\end{equation}

The constant cancels in the SNR, and may therefore be set to 1.

Combining these results, the value we will use to determine whether or
not our data $s$ contains the gravitational waveform $h$ (henceforth
called the \emph{template} waveform) is

\begin{equation}
\label{eq:snr}
\rho = \frac{\InnerProduct{s|h}}{\sqrt{\InnerProduct{h|h}}}
\end{equation}

The template has an unknown phase, denoted $\phi_0$ in
equation~\ref{eq:spa_waveform}.  As this term has no $f$ dependence it
gives rise to a constant of the form $\exp(i\phi_0)$, which can be
pulled out of the integral.  We can then maximize over this value by
taking the absolute value.

This result is valid for a segment of data of length $t$ seconds
and a waveform of the same length.  However, there may be a signal in
the data that does not end where the template does. We should
therefore evaluate~\ref{eq:snr} repeatedly, sliding the template so
that it ends at a different time for each iteration.  However, this
can be done in a single operation.  If $\tilde{h}(f)$ is the Fourier
transform of $h(t)$, then the Fourier transform of $h(t+\tau)$ is

\begin{equation*}
\tilde{h}(f)' = \int h(t+\tau) e^{2 \pi i f t} dt
= \int h(t') e^{2 \pi i f (t'-\tau)} dt'
= e^{-2 \pi i } \tilde{h}(f)
\end{equation*}

Substituting this into the matched filter,

\begin{equation}
\label{eq:snr_time_series}
\rho(\tau) = \frac{1}{\InnerProduct{h|h}}
\left\lvert \int e^{-2\pi i f \tau} \frac{\tilde{s}(f)
\tilde{h}^\star(f)}{S_n(f)}\,df \right\rvert
\end{equation}

where we have added the absolute value from the maximization over
$\phi_0$.  This is just the inverse Fourier transform of the quantity
$\tilde{s}(f)\tilde{h}(f)^\star/S_n$.  

Related to the SNR is the \emph{overlap} between two waveforms $h$ and
$h'$ with respect to a given PSD,


\begin{equation}
  \label{eq:OverlapDefinition}
  \Overlap{h|h'} \equiv \frac{\InnerProduct{h|h'}}{
    \sqrt{\InnerProduct{h|h} \InnerProduct{h'|h'}}}\ .
\end{equation}

This is a measure of how similar the two waveforms are. We can
eliminate artificial discrepancies created by misaligning the
waveforms by maximizing over the time and phase, as with the SNR.  We
will use this repeatedly in subsequent chapters.

\subsection{Trigger Selection}
\label{ssec:analysis_trigger_selection}

Equation~\ref{eq:prob_of_signal} says that there is a finite
probability of a \emph{false alarm}, random fluctuations mimicking a
signal.  We must therefore choose a threshold on $\rho(t)$ that is
high enough to keep the false alarm rate to an acceptable level, but
not so high as to prevent detection of realistic signals.  LIGO has
chosen 5.5 as this threshold.  However, it would be wasteful to store
every value in excess of this threshold.  The LIGO data is sampled
rapidly enough that adjacent points do not differ by values that are
large relative to numeric precision.  This feature is inherited by the
SNR time series.  Therefore, points close to a large value will also
be large, despite coming from the same event.  We therefore need only
consider the largest SNR.  This SNR,  the time at which it occurred,
and information about the template to be discussed below will
constitute a \emph{trigger}.

The probability of seeing two gravitational waves in an analysis time
is vanishingly small, but the possibility of a gravitational wave and
a random excursion above threshold is large enough that we must
consider it.  We therefore choose the largest SNR not from the whole
analysis, but from a smaller window.  A logical choice for the length
of this window is the time length of the template.  For pN waveforms
described in section~\ref{sec:PNWaveforms} this is defined as the time
from which the instantaneous frequency is 40 Hz to the time where it
becomes infinite.

The full trigger selection algorithm is:
\newpage

\begin{alltt}
for each sample point j
  if \(\rho\sb{j}\) > threshold
    if there is no event yet
      event\_start = j
      event\_snr   = \(\rho\sb{j}\)
    else if \(\rho\sb{j}\) > event\_snr
      event\_start = j
      event\_snr = \(\rho\sb{j}\)
    else if (j - event\_start) == template length
      record event
      event\_start = j
      event\_snr   = \(\rho\sb{j}\)
\end{alltt}

We will discuss some implications of this algorithm in
section~\ref{sec:daily_ihope_open_questions}.

\section{The $\chisq$ test}
\label{sec:ihope_chisq}

Consider again the SNR time series, equation~\ref{eq:snr_time_series},
which we now write as

\begin{equation*}
\rho(t) = \frac{1}{\InnerProduct{h|h}}
\int e^{-2\pi i f t} \frac{\tilde{h}^\star(f)}{S_n(f)} \cdot \tilde{s}(f) \,df
\end{equation*}

By the convolution theorem this becomes

\begin{equation*}
\rho(t) = \frac{1}{\InnerProduct{h|h}}
h(-t) \star S(t) \star s(t)
\end{equation*}

where $S(t)$ is the inverse Fourier transform of $1/S_n(f)$.  If the
signal is an impulse, $s(t) = \delta(t)$, then the response is the
time-reversed template (``fuzzed'' by the noise curve).  Given a sharp
feature in the data the SNR will therefore be elevated, even though
the data looks nothing like a gravitational wave.  As we will see in
chapter~\ref{ch:detchar}, this is a very practical concern.  More
generally however this demonstrates that the SNR alone is not
sufficient to distinguish signals from noise in the presence of
non-Gaussian features of the data.

We therefore supplement the analysis with the $\chisq$
test~\cite{Allen:2004}.  The idea is to check not only that the SNR is
large, but also that it was accumulated over the frequency integration
in a way consistent with a real signal.  We do this by dividing the
template into $p$ sub-templates $h_i$, which match the original
template between frequencies $f_i$ and $f_{i+1}$ and are zero
elsewhere and the $f_i$ are chosen such that

\begin{equation*}
\int_{f_i}^{f_{i+1}} \frac{|h_i|^2}{S_n(f)}\,df
= \frac{1}{p}
\int_{f_0}^{f_c} \frac{|h_i|^2}{S_n(f)}\,df
\end{equation*}

where $f_0$ is the starting frequency (40 Hz in LIGO) and
$f_c$ is, as in equation~\ref{eq:spa_waveform}, the frequency at which
we terminate the waveform.

We then filter with these sub-templates independently to produce 
the $p$ time series $\rho_i(t)$ and construct the quantity

\begin{equation}
\label{eq:chisq}
\chi^2(t) = \sum_{i=1}^p \left(\rho_i(t) - \frac{\rho(t)}{p}\right)^2
\end{equation}

If the signal exactly matches the template $\chi^2$ will be zero, and
it will increase as the signal and template deviate.

We incorporate this information in the analysis by constructing a
quantity, $\newsnr$ (new SNR), which downweights the SNR by $\chisq$,

\begin{equation}
\label{eq:new_snr}
\newsnr^2 = \begin{cases}
 \rho^2, & \chi^2_{r} \leq 1, \\ 
 \frac{\rho^2}{[(1+(\chi_r^2)^3)/2]^{1/6}}, \ & \chi^2_{r} > 1,
\end{cases}  
\end{equation}


\section{Choosing the templates}
\label{sec:bank_metric}

We have thus far referred to the $h$ as ``the template'', but recall
from equation~\ref{eq:spa_waveform} that the waveforms are depend on
the parameters of the binary, such as total mass $M$ and symmetric
mass ratio $\eta$.  As the values of these parameters diverge between
the signal  and template the SNR will decrease.  We must therefore
construct a \emph{bank} of templates arranged to capture, to within
some acceptable loss of SNR, all the signals of interest.  To do so we
consider the space of templates as a manifold, as in
chapter~\ref{ch:theory}, and we use the parameter values (or functions
of these values) as coordinates.  The distance between two points
$\mathbf{p}$ and $\mathbf{q}$, with coordinates=parameters $p_i$ and
$q_i$,  is defined in terms of the overlap of templates at those
parameters

\begin{equation*}
d = 1 - \Overlap{h(\mathbf{p})|h(\mathbf{q})}
\end{equation*}

We then seek a set of templates, $\{h_i\}$ such that within a region
of interest every point in the manifold is ``sufficiently close'' to
at least one template:

\begin{equation*}
\forall \mathbf{p}, \min_i \Overlap{h(\mathbf{p})|h_i} < x
\end{equation*}

Such a bank will ensure that the loss in SNR from using the bank
instead of testing the entire continuum of parameters is less than
$x\%$.  In LIGO we typically require no more than a 3\% loss in SNR.
As the distance to which we can detect signals scales with SNR and
volume is the cube of distance, this corresponds to approximately a
10\% loss in event rate.

It is possible to construct the bank \emph{stochastically}:

\begin{itemize}
\item Choose a point in the manifold at random

\item If the overlap with any already-placed template is greater than the
minimal match, discard it

\item Otherwise, add it to the set and continue

\item Repeat until there have been $N$ consecutive rejected new
candidates, where $N$ is chosen to give a reasonable probability that
the space has been covered.
\end{itemize}

In many cases however we can do better then this.  Since we are
interested in distances on a manifold it makes sense to seek a metric
on this space.  Such a metric can be obtained by expanding the
overlap function~\cite{Owen:1995tm, Owen:1998dk}

\begin{equation*}
\label{eq:bank_matric}
\Overlap{h(\mathbf{\lambda})|h(\mathbf{\lambda} +
\Delta\mathbf{\lambda})}
\approx 1 - \frac{1}{2} 
\frac{\partial^2 \Overlap{h(\mathbf{\lambda})|h(\mathbf{\lambda} +
\Delta\mathbf{\lambda})}}{\partial \Delta \lambda_i \partial \Delta \lambda_j}\bigg|_{\Delta
\mathbf{\lambda}=0} (\Delta
\lambda_i) (\Delta \lambda_j)
\end{equation*}

where we can drop the linear term because the overlap is a maximum at
$\Delta \mathbf{\lambda} = 0$.  When using frequency-domain,
stationary-phase templates of the form~\ref{eq:spa_waveform}, the
calculation of this metric can be done analytically, and gives a
result in terms of moments of the noise curve

\begin{equation*}
I(q) = S_n(f_0) \int_{f_0}^{f_c} \frac{x^{-q/3}}{S_n(x f_0)}\,dx
\end{equation*}

where $f_0$ is a chosen reference frequency.

The metric can then be used to efficiently lay out a grid of
templates.  In general it is impossible to lay out a grid on a curved
surface such that every point is the same distance from its nearest
neighbors, but the metric on the template manifold is approximately
flat and, when written in appropriate coordinates, the coefficients
are constant.


\section{The search pipeline}

We now discuss how the above elements are incorporated into 
a gravitational wave search.  The system is collectively known as a
\emph{pipeline}, as it may be thought of as a series of steps through
which the data flows.

We now present a very high-level overview of how the above elements
were used in the search for gravitational waves from the coalescence
of compact binaries.  We focus in particular on the search for
gravitational waves from the coalescence of binary systems in LIGO's
6th science run (denoted "S6", July 7, 2009 - October 20, 2010) which
overlapped Virgo's second ("VSR2", July 7, 2009 - January 11, 2010),
and third ("VSR3", August 11, 2010 - October 20, 2010) science runs.
For more details, see \Note{Collin's thesis}.

In each IFO the analysis is broken into 2048-second segments.  This is
done for computational efficiency, as well as to restrict to timespans
over which the PSD is nearly stationary.  The times covered by each
instrument may not overlap, but we ignore this minor complication.

First, the data is filtered to remove power below 40 Hz.  The seismic
noise below this frequency is orders of magnitude greater than  the
noise at higher frequencies, and without this filtering any signal
would be entirely swamped.

The PSD for each IFO is then calculated by \emph{Welch's method}.  The
2048 seconds are split into 15 256-second chunks, overlapping by 128
seconds.  The PSD of each chunk is then calculated using the defining
equation~\ref{eq:psd1}.  The final PSD is obtained by taking the
median values of each frequency bin. This is done in order to make the
PSD estimation robust against loud, short events.  As an extreme
example, if there were a loud gravitational wave in the data the PSD
would be elevated, paradoxically suppressing the SNR.  This gives a
single PSD spanning 256 seconds.

The PSD is then used to construct the template bank.  In S6/VSR2,3 we
used stationary-phase templates taken to 3.5 pN order in phase
evolution.  See chapter~\ref{ch:comparison} for more on this choice.

We then break the 2048-second segment into 256-second chunks (as that
is the duration for which the PSD is valid) and filter the data with
each template in the bank.  The $\chisq$ test is not enabled at this
stage, as it is computationally expensive.  The segments are again
overlapped, due to issues with the first and final 64 seconds of each
segment being corrupted.  See~\cite{DBrownThesis} for more on this
issue.

The PSD used at this stage is not exactly the PSD that was calculated,
it has been modified to prevent a loud impulse from corrupting the
entire chunk.  We return to this issue in section~\ref{ssec:penguins},
but for the moment recall that the response of the matched filter to
an impulse can elevate the SNR for an extended time.

The outcome of this stage is a set of triggers for each IFO.  We then
apply a \emph{coincidence test} by testing whether each trigger is
close (in the sense of the metric equation~\ref{eq:bank_matric}) to
triggers from the other instruments.  We allow the trigger time to
differ by the maximum time it could take a gravitational wave to
travel between instruments.

There is now a second stage of the process.  Templates in each bank
that have not produced coincident triggers are discarded.  The
filtering is then repeated, now with $\chisq$ enabled.  There is then
another coincidence test and the resulting triggers, now identified as
\emph{foreground triggers} are assigned a \emph{cumulative new SNR}
value

\begin{equation*}
\rho_{\textrm{new, cumulative}}^2 = \sum_i \rho_{\textrm{new}, i}^2
\end{equation*}


In order to determine how significant a foreground trigger is it must
be compared against the background distribution.  In pure Gaussian
noise the probability distribution for cumulative new SNR could be
calculated from equation~\ref{eq:prob_of_signal}.  As the real data is
not Gaussian, this distribution must instead be measured.  We do so by
performing \emph{time slides}.  The data from each IFO is slid by more
than the light-travel time between instruments.  Assuming at most one
gravitational wave in the data, this ensures that any coincidences are
entirely due to triggers produced by noise.  We repeat this 100 times
in order to build up more statistics.  At the end we have a
probability (or equivalently a rate) of obtaining triggers at each
combined new SNR value.  The foreground triggers are then compared to
this distribution, those with values that are sufficiently
rare/improbable are potential detection candidates, which are then
subjected to extensive follow up analysis.

The order to test and tune the pipeline we perform numerous
\emph{software injections}, where simulated signals are added to the
data before the first filtering step.  Changes to the pipeline can be
tested by examining the efficiency of the search, the number of
injections recovered as a fraction of the number injected in a given
region of parameter space.

The LIGO and Virgo collaborations also perform end-to-end tests with
\emph{hardware injections}, in which signals are added to the data by
moving the \texttt{ETMX} mirror.  Generally the times and the
parameters of the injections are known, allowing complete end-to-end
tests of the pipeline.  However, there have been ``blind'' injection
challenges, signals injected at \texttt{ETMY} by a small group within
the collaboration which are not announced.  We will have much more to
say about one such injection in section~\ref{sec:applications_dog}.

\section{Conclusions}

We have derived the matched filter as the optimal search for a known
signal in Gaussian noise.  We then proceeded to construct an entire
gravitational wave search pipeline using matched filtering as the core
concept.

The construction of this pipeline involved making many choices: the
template waveforms, the frequency at which to terminate the templates,
the spacing of the bank, the region of parameter space to cover, the
SNR threshold, and so on.  It is possible and useful to test
these choices against pN signals, as is done in software and hardware
injections.   However, it is known that these waveforms to not capture
the full physics of the systems for which we are looking.  There is
therefore strong impetus to test the pipeline against signals from
numerical relativity.  This topic is the basis for the next four
chapters.



