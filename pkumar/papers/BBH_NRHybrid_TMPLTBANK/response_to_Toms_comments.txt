Tom's comments:-

-------------

I don't see the argument why you would use this method in preference to a waveform model such as EOBNR(v2+) which can be made sufficiently accurate in fitting NR and can interpolate between different q values. Are there clear benefits of an NR / hybrid bank? I see some arguments against, eg inflexibility, also computational cost of filtering, coincidence and event processing, if (as seems inevitable) the NR bank contains more templates than a standard variable-q bank laid out via a metric or stochastic method.  Though I can't tell how many more, because the paper doesn't say...

A:
Traditionally, IMR waveform models, calibrated to agree with NR 
waveforms that span a few tens of cycles before merger, are used as
search templates. Current BBH simulation technology is rapidly making
progress with increasing numbers of longer high accuracy simulations 
becoming available. This paper proposes an alternate to the traditional
approach, by demonstrating the feasibility of using NR/hybrid waveforms
directly as templates. For a proof of principle, we focus on 
non-spinning BBHs at present, but we aim to extend this to spinning 
binaries in future.

The bound we derive for the intrinsic errors of the hybrids is
independent of analytic waveform models. This allows us to have 
reliable estimates of waveform errors, that we argue should be taken
into account when constructing template banks.

This has been added to the introduction, phrased as follows:
"Constructing template banks for gravitational wave searches has
been a long sought goal for NR. Traditionally, intermediary waveform
models are calibrated against numerical simulations and then
used in template banks for LIGO searches~\cite{Abadie:2011kd,
Aasi:2012rja}. In this paper we explore an alternative to this
traditional approach, proposing the use of NR waveforms themselves
and hybrids constructed out of them as search templates.
For a proof of principle, we focus on the non-spinning BBH space, 
with the aim of extending to spinning binaries in future work. We
investigate exactly where in the mass space can the existing NR 
waveforms/hybrids be used as templates, finding that only six 
simulations are sufficient to cover binaries with 
$m_{1,2}\gtrsim 12M_\odot$ upto mass-ratio $10$. This method can
also be used as a guide for the placement of parameters for future
NR simulations. Recent work has shown that existing PN waveforms 
are sufficient for aLIGO searches for 
$M=m_1+m_2\lesssim 12M_\odot$~\cite{CompTemplates2009,Brown:2012nn}.
To extend the NR/hybrid bank coverage down to 
$M\simeq 12M_\odot$, we demonstrate that a total of $26$ 
simulations would be sufficient. The template banks are 
constructed with the requirement that the net SNR recovered for 
any BBH signal should remain above $96.5\%$ of its optimal value.
Enforcing this tells that that these $26$ simulations would be 
required to be $\sim 50$ orbits long. This goal is achievable,
given the recent progress in simulation 
technology~\cite{MacDonald:2012mp,Mroue:2013xna,BelaLongSimulation}. 
Our template banks are viable for GW searches with aLIGO, and the 
framework for using hybrids within the LIGO-Virgo software 
framework has been demonstrated in the NINJA-2
collaboration~\cite{NINJA2:2013inPrep}. In this paper, we also 
derive waveform modeling error bounds which are independent of
analytical models. These can be extended straightforwardly to 
assess the accuracy of such models."

On the question of increased computational cost, the number of 
templates required to cover down to component masses of 12 Msun is
627. The 2PN metric based algorithm yields 522 templates for 97% MM
and 736 for 98% MM. Not only is the size of the hybrid template 
bank comparable to the metric based one, the absolute size of the
bank is unlikely to be computationally expensive compared to
NSBH and BNS template banks.

The numbers quoted in the paper, i.e. 2457 templates, includes 
templates that cover the region with component masses below 12 Msun
as well, as shown in Figs.6-8. I have quoted the more relevant 
number, i.e. of templates required to cover down to 12 Msun.
Thank you for pointing this out..

-------------
p.2 seems to say the point at which the merger-ringdown starts adding signal power in LIGO is around 25-35 Msun. Previous theoretical studies put this around 12-15 Msun so I'm not sure why there are larger numbers quoted.

A:
"Higher mass binaries, with M >= 25 - 35Msun, are expected
to have a significant fraction of signal power coming from
the merger phase, as it occurs within the sensitive band of
LIGO. Complete inspiral-merger-ringdown EOB waveforms
were used to search for GWs from such BBH systems during
the LIGO-Virgo observation period between 2005-07 and
2009-10"

This was meant to imply that for binaries with M >=25-35Msun, which are
the lowest total masses that the high-mass searches focused on,
merger-ringdown definitely contributes a significant fraction of signal
power; and not that these masses are the lowest masses where the
merger-ringdown begins to contribute. I've clarified the wording to:

"Early LIGO-Virgo searches employed template banks of Post-Newtonian (PN)
inspiral waveforms~\cite{Colaboration:2011nz,Abadie:2010yb,Abbott:2009qj,
Abbott:2009tt,Messaritaki:2005wv}, while more recent searches targeting 
high mass BBHs used complete inspiral-merger-ringdown (IMR) waveform 
templates~\cite{Abadie:2011kd,Aasi:2012rja}."

-------------
p.2 claims that a mother template method involving resampling/rescaling hybrids at constant q would be 'relatively computationally inexpensive' for searches. But relative to what, and in what context? Is the computational cost of producing the NR waveforms and hybrids included? Would any computational saving (presumably in generating templates?) be significant next to the cost of actually performing the matched filter? Sathya's Mother Template paper doesn't claim there would be computational savings in carrying out an actual search.

A:
"Such a bank would be relatively computationally inexpensive
to use in detection searches, as is the case for using 
frequency-domain analytic closed-form models for templates."

This statement is focused at the cost of generating templates in a bank,
assuming we have hybrids available on disk.

By pre-loading the hybrids corresponding to the lowest total mass for each
mass-ratio, every other template can be obtained by re-scaling them
appropriately in frequency domain. This would be relatively computationally
inexpensive as compared to the cost of generating and fourier transforming
time domain templates for a metric-based or a non-restricted stochastic bank.
Put another way, the cost of generating the hybrid template bank would be
comparable to a similar bank of TaylorF2/Phenom? waveforms, and lesser 
than the same for a bank of EOB waveforms. I've clarified the wording to:

"Used in detection searches, such a bank would be computationally inexpensive 
to generate relative to a bank of time-domain modeled waveforms, as is the 
case for frequency-domain closed-form analytic templates."


-------------
On p.3 the paper refers to 'daunting computational cost' of performing FFTs (!) for each template if they start off in the time domain. This sounds just wrong and I don't see any evidence for it, the highmass search routinely FFTs several thousand EOBNR templates within a single job and it's not the dominant cost - I would guess it is also insignificant next to the cost of generating the templates in the time domain.

A:
This is a fair point that the cost of FFT is definitely not 'daunting'
compared to that of generating templates in the time domain. I have 
changed

"Past GW searches have extensively used the TaylorF2 approximant, as it has
a closed form and saves the daunting computational cost of a numerical 
fourier-transform for each template"

to:

"Past GW searches have extensively used the TaylorF2 approximant, as it has
a closed form and mitigates the computational cost of generating and numerically 
fourier-transforming time-domain templates"

-------------
If you think computational cost of generating (either TD or FD) templates will be a significant issue for searches *compared to matched filtering a year of data through them* then there are many alternative methods to address it. I can't see if the paper is making a claim that there are computational cost issues or not. [It certainly *is* an problem for BBH parameter estimation where the demand for waveform computation is much higher.]

A:
This paper is meant to demonstrate the feasibility of using numerical-PN
hybrid waveforms as templates. Whenever we refer to computational cost 
mitigation, we mean to imply that (i) the total number of templates in the
hybrid bank is comparable to one constructed with the 2PN placement metric,
and (ii) the cost of generating templates could be decreased by pre-generating
one template for each mass-ratio. This would be a more prominent effect when 
the method is extended to aligned-spin systems, and in this paper we simply
point this out without stressing upon it.

-------------
One thing that would be very useful to include is simply comparing the number of templates in the NR or hybrid banks to a standard metric placement as in Ref.[109] or a 'normal' stochastic bank (using, say, EOBNRv2 templates). This is important to know for doing searches if we do care about computational cost.

For what it's worth, lalapps_tmpltbank (with a *2PN* metric) with minimum component mass 12, maximum total mass 200 (ZDHP, 15 cutoff etc.) and intended minimal match 0.98 produces 736 templates (522 at nominal 0.97 minimal match) so 2000-plus is significantly more. [For LSC members :
https://atlas1.atlas.aei.uni-hannover.de/~tdent/LSC/harald_tmplt.png ]

A:
As above:
The number of templates required to cover down to component masses of 12 Msun is
627. The 2PN metric based algorithm yields 522 templates for 97% MM and 736 for 
98% MM. Not only is the size of the hybrid template bank comparable to the metric
based one, the absolute size of the bank is unlikely to be a computationally 
expensive compared to NSBH and BNS template banks.

-------------
I think it would be appropriate to have a bit more discussion of subdominant (non-2,2) waveform modes given that they may contribute significantly for higher mass ratios and/or at the upper end of the mass range, not just for precessing waveforms as implied on p.14. It is not clear whether we want to perform a dominant-mode only search all the way up to 200 solar masses and for relatively asymmetric systems (though it's also not clear what the alternative is).

A:
I have modified the discussion on pg. 14, to reflect that subdominant modes 
become increasingly important at higher masses (and mass-ratios), not for
precessing binaries alone but also for non-spinning or aligned-spin binaries,
and is something that should be considered in future work.

-------------
I think the material about hybridization errors is interesting, that is something that will have to be watched closely as more NR waveforms become available...

Cheers, Tom


-- 
-----------------------------------
Institute for Gravitational Physics
(Albert Einstein Institute)
Hannover, Germany

